{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map data visualisation\n",
    "\n",
    "This file will be used to visualize the geolocation in various ways "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we import the python packages that will be relevant for this project\n",
    "\n",
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re #for regular expression and data cleaning\n",
    "import geotext #for extracting location from text\n",
    "import geopy #for geocoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we need to extract ther data\n",
    "\n",
    "### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>like_count</th>\n",
       "      <th>rt_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>isVerified</th>\n",
       "      <th>language</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-21 03:30:04+00:00</td>\n",
       "      <td>तुर्की में सोमवार देर रात भूंकप के तेज झटके मह...</td>\n",
       "      <td>['ATDigital', 'Turkey', 'Earthquake', 'TurkeyE...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19727712</td>\n",
       "      <td>True</td>\n",
       "      <td>hi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Media Studio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-21 03:29:07+00:00</td>\n",
       "      <td>New search &amp;amp; rescue work is in progress in...</td>\n",
       "      <td>['Hatay', 'earthquakes', 'Türkiye', 'TurkiyeQu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5697</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-21 03:29:04+00:00</td>\n",
       "      <td>Can't imagine those who still haven't recovere...</td>\n",
       "      <td>['Turkey', 'earthquake', 'turkeyearthquake2023...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-21 03:28:06+00:00</td>\n",
       "      <td>its a highkey sign for all of us to ponder ove...</td>\n",
       "      <td>['turkeyearthquake2023', 'earthquake', 'Syria']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-21 03:27:38+00:00</td>\n",
       "      <td>Turkiye Earthquake: तुर्किए में फिर आया भूकंप ...</td>\n",
       "      <td>['turkey', 'earthquake', 'turkiye', 'india', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>und</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "0  2023-02-21 03:30:04+00:00   \n",
       "1  2023-02-21 03:29:07+00:00   \n",
       "2  2023-02-21 03:29:04+00:00   \n",
       "3  2023-02-21 03:28:06+00:00   \n",
       "4  2023-02-21 03:27:38+00:00   \n",
       "\n",
       "                                             content  \\\n",
       "0  तुर्की में सोमवार देर रात भूंकप के तेज झटके मह...   \n",
       "1  New search &amp; rescue work is in progress in...   \n",
       "2  Can't imagine those who still haven't recovere...   \n",
       "3  its a highkey sign for all of us to ponder ove...   \n",
       "4  Turkiye Earthquake: तुर्किए में फिर आया भूकंप ...   \n",
       "\n",
       "                                            hashtags  like_count  rt_count  \\\n",
       "0  ['ATDigital', 'Turkey', 'Earthquake', 'TurkeyE...           0         0   \n",
       "1  ['Hatay', 'earthquakes', 'Türkiye', 'TurkiyeQu...           1         0   \n",
       "2  ['Turkey', 'earthquake', 'turkeyearthquake2023...           0         0   \n",
       "3    ['turkeyearthquake2023', 'earthquake', 'Syria']           0         0   \n",
       "4  ['turkey', 'earthquake', 'turkiye', 'india', '...           0         0   \n",
       "\n",
       "   followers_count  isVerified language coordinates place  \\\n",
       "0         19727712        True       hi         NaN   NaN   \n",
       "1             5697        True       en         NaN   NaN   \n",
       "2                1       False       en         NaN   NaN   \n",
       "3                3       False       en         NaN   NaN   \n",
       "4               17       False      und         NaN   NaN   \n",
       "\n",
       "                 source  \n",
       "0  Twitter Media Studio  \n",
       "1       Twitter Web App  \n",
       "2   Twitter for Android  \n",
       "3   Twitter for Android  \n",
       "4   Twitter for Android  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./archive/tweets.csv\", nrows=10000)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would need to clean the data. We would need to remove the URLs, hashtags, mentions, and emojis. We would also need to remove the punctuations and convert the text to lowercase. \n",
    "\n",
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
    "    text = re.sub(r'#', '', text) # remove hashtags\n",
    "    text = re.sub(r'\\s+', ' ', text) # remove extra whitespace\n",
    "    return text\n",
    "\n",
    "data['content'] = data['content'].apply(clean_text)\n",
    "\n",
    "# Transform the date column to datetime format\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['date'] = data['date'].dt.strftime('%Y-%m-%d %H:%M:%S') # stolen from main file\n",
    "\n",
    "data = data[data['language'] == 'en'] # only english tweets -- This to be deleated when we get more data\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to find where the tweets are and fill in the missing values. This can be done with natural language processing. We are trying to see what city or specific location the tweet is mentioned in it. \n",
    "\n",
    "### Location extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of tweets with location: 1315\n",
      "Amount of tweets with distance: 31\n"
     ]
    }
   ],
   "source": [
    "# Create a new column for location mentioned in text.\n",
    "data['location'] = data['content'].apply(lambda x: geotext.GeoText(x).cities)\n",
    "\n",
    "\n",
    "data['location'] = data['location'].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "\n",
    "# Create a new column with the distance from location after finding *km or *miles in text.\n",
    "data['distance'] = data['content'].apply(lambda x: re.findall(r'\\d+km|\\d+miles', x))\n",
    "\n",
    "# Extract the number from the distance column and convert it to float.\n",
    "data['distance'] = data['distance'].apply(lambda x: float(re.findall(r'\\d+', x[0])[0]) if len(x) > 0 else None)\n",
    "\n",
    "# Print the amount of tweets with location and distance.\n",
    "print(f\"Amount of tweets with location: {len(data[data['location'].notnull()])}\")\n",
    "print(f\"Amount of tweets with distance: {len(data[data['distance'].notnull()])}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
